{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa32c25",
   "metadata": {},
   "source": [
    "## This script transforms the BDD100K dataset into Yolov8 format and filter specific classes.\n",
    "\n",
    "__[Berkeley Deep Drive Dataset (BDD100K)](https://www.vis.xyz/bdd100k/)__: A Diverse Driving Dataset for Heterogeneous Multitask Learning (Images 100K) is a dataset for instance segmentation, semantic segmentation, object detection, and identification tasks. The dataset can be downloaded from __[here](https://dl.cv.ethz.ch/bdd100k/data/)__\n",
    "\n",
    "BDD 100K has 10 classes for object detection\n",
    "1. pedestrian\n",
    "2. rider\n",
    "3. car\n",
    "4. truck\n",
    "5. bus\n",
    "6. train\n",
    "7. motorcycle\n",
    "8. bicycle\n",
    "9. traffic light\n",
    "10. traffic sign"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3359f",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "21"
    }
   },
   "source": [
    "### Filter specific Class\n",
    "First we filter specific labels (in this case, traffic signs) from the BDD dataset by reading the original labels from a JSON file, extracting only the labels related to traffic signs, copying the corresponding images to a new directory, and saving the filtered labels into a new JSON file. It ensures that only the relevant traffic sign data is retained and all other classes are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9b05f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Paths to the directories and files\n",
    "image_dir = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/images/100k/val/\"\n",
    "label_file = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/labels/det_val.json\"\n",
    "output_label_file = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/labels/det_val_traffic_signs.json\"\n",
    "output_image_dir = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/images/100k/val_traffic_signs\"\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_image_dir, exist_ok=True)\n",
    "\n",
    "# Load the JSON file\n",
    "with open(label_file, 'r') as file:\n",
    "    try:\n",
    "        data = json.load(file)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        raise\n",
    "\n",
    "# Filter the labels\n",
    "filtered_data = []\n",
    "for item in data:\n",
    "    try:\n",
    "        if 'labels' in item:  # Check if 'labels' key exists\n",
    "            traffic_sign_labels = [label for label in item['labels'] if label.get('category') == 'traffic sign']\n",
    "            if traffic_sign_labels:\n",
    "                filtered_labels = [{\n",
    "                    'category': label['category'],\n",
    "                    'box2d': label['box2d']\n",
    "                } for label in traffic_sign_labels]\n",
    "\n",
    "                filtered_data.append({\n",
    "                    'name': item['name'],\n",
    "                    'labels': filtered_labels,\n",
    "                    'attributes': item.get('attributes', {})  # Include attributes if present\n",
    "                })\n",
    "\n",
    "                # Copy the corresponding image\n",
    "                src_image_path = os.path.join(image_dir, item['name'])\n",
    "                dst_image_path = os.path.join(output_image_dir, item['name'])\n",
    "                if os.path.exists(src_image_path):\n",
    "                    shutil.copy(src_image_path, dst_image_path)\n",
    "        else:\n",
    "            print(f\"No 'labels' key found in item: {item['name']}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error processing item {item['name']}: {e}\")\n",
    "\n",
    "# Save the filtered labels into a new JSON file\n",
    "with open(output_label_file, 'w') as file:\n",
    "    json.dump(filtered_data, file, indent=4)\n",
    "\n",
    "print(f\"Filtered labels saved to {output_label_file}\")\n",
    "print(f\"Images copied to {output_image_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9981aa09",
   "metadata": {},
   "source": [
    "### Remove Extra images\n",
    "Then we will Delete all the unnecessary images that do not contain our labels(traffic signs). For that a list of image names will be generated by the the .json of filtered labels and then all the images will be deleted that will not be present in that list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f73de90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images deleted: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Path to the directory containing images\n",
    "image_dir = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/images/100k/train/\"\n",
    "\n",
    "# Path to val.json file\n",
    "val_json_file = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/labels_csv/train.json\"\n",
    "\n",
    "# Load val.json to get list of image names\n",
    "with open(val_json_file, 'r') as file:\n",
    "    try:\n",
    "        val_data = json.load(file)\n",
    "        val_image_names = [item['name'] for item in val_data]\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error loading JSON file: {e}\")\n",
    "        exit(1)\n",
    "\n",
    "# Iterate through images in the directory\n",
    "deleted_count = 0\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n",
    "        if filename not in val_image_names:\n",
    "            file_path = os.path.join(image_dir, filename)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "                deleted_count += 1\n",
    "                print(f\"Deleted: {filename}\")\n",
    "            except OSError as e:\n",
    "                print(f\"Error deleting {filename}: {e}\")\n",
    "\n",
    "print(f\"Total images deleted: {deleted_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46ec0a",
   "metadata": {},
   "source": [
    "### Convert BDD dataset to Yolo format\n",
    "\n",
    "A typical Yolov8 format looks like this\n",
    "```\n",
    "dataset/\n",
    "│\n",
    "├── images/\n",
    "│   ├── train/\n",
    "│   ├── val/\n",
    "│   └── test/    # Optional\n",
    "│\n",
    "├── labels/\n",
    "│   ├── train/\n",
    "│   ├── val/\n",
    "│   └── test/    # Optional\n",
    "│\n",
    "└── data.yaml\n",
    "```\n",
    "The labels directory mirrors the images directory structure and contains the label files corresponding to each image. Each label file has the same name as its corresponding image file but with a .txt extension. These label files contain the annotation data in YOLO format.\n",
    "\n",
    "Each label file contains annotations for a single image, with each line representing one object. The format for each line is\n",
    "\n",
    "` class_id x_center y_center width height `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3656c62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion to YOLO format completed.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def convert_to_yolo_format(json_file, image_dir, output_dir):\n",
    "    with open(json_file, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    for item in data:\n",
    "        image_name = item['name']\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        \n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"Image file {image_path} not found. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        image_width, image_height = get_image_size(image_path)\n",
    "        \n",
    "        if image_width == 0 or image_height == 0:\n",
    "            print(f\"Image {image_path} has invalid dimensions. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        txt_filename = os.path.splitext(image_name)[0] + \".txt\"\n",
    "        txt_path = os.path.join(output_dir, txt_filename)\n",
    "        \n",
    "        with open(txt_path, 'w') as txt_file:\n",
    "            for label in item['labels']:\n",
    "                category = label['category']\n",
    "                box = label['box2d']\n",
    "                x1, y1 = box['x1'], box['y1']\n",
    "                x2, y2 = box['x2'], box['y2']\n",
    "                \n",
    "                # Calculate center and dimensions relative to image size\n",
    "                center_x = (x1 + x2) / 2 / image_width\n",
    "                center_y = (y1 + y2) / 2 / image_height\n",
    "                width = (x2 - x1) / image_width\n",
    "                height = (y2 - y1) / image_height\n",
    "                \n",
    "                # Write to YOLO format text file\n",
    "                txt_file.write(f\"{category} {center_x} {center_y} {width} {height}\\n\")\n",
    "\n",
    "def get_image_size(image_path):\n",
    "    try:\n",
    "        from PIL import Image\n",
    "        with Image.open(image_path) as img:\n",
    "            width, height = img.size\n",
    "            return width, height\n",
    "    except Exception as e:\n",
    "        print(f\"Error getting image size for {image_path}: {e}\")\n",
    "        return 0, 0\n",
    "\n",
    "# Paths to directories and files\n",
    "image_dir_train = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/images/100k/train/\"\n",
    "image_dir_val = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/images/100k/val/\"\n",
    "train_json_file = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/labels/train.json\"\n",
    "val_json_file = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/labels/val.json\"\n",
    "output_dir_train = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd_yolo/train/\"\n",
    "output_dir_val = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd_yolo/val/\"\n",
    "\n",
    "# Convert train set\n",
    "convert_to_yolo_format(train_json_file, image_dir_train, output_dir_train)\n",
    "\n",
    "# Convert validation set\n",
    "convert_to_yolo_format(val_json_file, image_dir_val, output_dir_val)\n",
    "\n",
    "print(\"Conversion to YOLO format completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5260757a",
   "metadata": {},
   "source": [
    "### Label Replacement\n",
    "Once the all the .txt files are generated with required yolo format, their class_id remains as string. For example: your each label file will look like this\n",
    "\n",
    "traffic_sign 10.43654 34.2345 2.098 1.30955\n",
    "\n",
    "but the yolo accepts only int as the class_id, not a string, so we have to replace the traffic_sign with an int in all the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5817e381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the path to the directory containing the label files\n",
    "label_dir = '/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k/labels/val'\n",
    "\n",
    "# Function to replace \"traffic sign\" with 0 in a file\n",
    "def replace_label(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        for line in lines:\n",
    "            # Replace \"traffic sign\" with 0\n",
    "            new_line = line.replace('traffic sign', '0')\n",
    "            file.write(new_line)\n",
    "\n",
    "# Iterate over all .txt files in the directory\n",
    "for file_name in os.listdir(label_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(label_dir, file_name)\n",
    "        replace_label(file_path)\n",
    "\n",
    "print(\"Label replacement completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460832c0",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "To view if the conversion from the BDD to yolo format is successful, we introduced a snippet that extracts the labels from the txt files and create bounding box on the images and then save them at desired directory. This way you can ensure that all the labels are correctly converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a766b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "def load_labels(label_file):\n",
    "    with open(label_file, 'r') as file:\n",
    "        labels = file.readlines()\n",
    "    return [list(map(float, line.strip().split())) for line in labels]\n",
    "\n",
    "def draw_bounding_boxes(image, labels, width, height):\n",
    "    for label in labels:\n",
    "        class_id, x_center, y_center, w, h = label\n",
    "        x_center *= width\n",
    "        y_center *= height\n",
    "        w *= width\n",
    "        h *= height\n",
    "        x1 = int(x_center - w / 2)\n",
    "        y1 = int(y_center - h / 2)\n",
    "        x2 = int(x_center + w / 2)\n",
    "        y2 = int(y_center + h / 2)\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    return image\n",
    "\n",
    "def process_images(images_folder, labels_folder, output_folder):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for image_file in os.listdir(images_folder):\n",
    "        if image_file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "            image_path = os.path.join(images_folder, image_file)\n",
    "            label_path = os.path.join(labels_folder, image_file.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt'))\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                image = cv2.imread(image_path)\n",
    "                height, width, _ = image.shape\n",
    "                labels = load_labels(label_path)\n",
    "                image_with_boxes = draw_bounding_boxes(image, labels, width, height)\n",
    "                output_path = os.path.join(output_folder, image_file)\n",
    "                cv2.imwrite(output_path, image_with_boxes)\n",
    "\n",
    "images_folder = '/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k_cropped/images/100k/val/'\n",
    "labels_folder = '/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k_cropped/labels/100k/val/'\n",
    "output_folder = '/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k_view_boundingBox/val/'\n",
    "\n",
    "process_images(images_folder, labels_folder, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c576333",
   "metadata": {},
   "source": [
    "### Tiling images (OPTIONAL) \n",
    "If the object size are very small as compared to the image size(like traffic signs), then it is very difficult to detect them. For that a technique named Tiling is used, this method slice up the images into smaller chunks and adjusting the labels according with it. This way, the models accuracy drastically increase, but it only works well only if the object sizes are very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from shapely.geometry import Polygon\n",
    "from shutil import copyfile\n",
    "\n",
    "def tiler(imnames, new_image_path, new_label_path, falsepath, slice_size, ext):\n",
    "    for imname in imnames:\n",
    "        im = Image.open(imname)\n",
    "        imr = np.array(im, dtype=np.uint8)\n",
    "        height = imr.shape[0]\n",
    "        width = imr.shape[1]\n",
    "        labname = imname.replace('images', 'labels').replace(ext, '.txt')\n",
    "        labels = pd.read_csv(labname, sep=' ', names=['class', 'x1', 'y1', 'w', 'h'])\n",
    "        \n",
    "        # Rescale coordinates from 0-1 to real image height and width\n",
    "        labels[['x1', 'w']] = labels[['x1', 'w']] * width\n",
    "        labels[['y1', 'h']] = labels[['y1', 'h']] * height\n",
    "        \n",
    "        boxes = []\n",
    "        \n",
    "        # Convert bounding boxes to shapely polygons\n",
    "        for _, row in labels.iterrows():\n",
    "            x1 = row['x1'] - row['w']/2\n",
    "            y1 = (height - row['y1']) - row['h']/2\n",
    "            x2 = row['x1'] + row['w']/2\n",
    "            y2 = (height - row['y1']) + row['h']/2\n",
    "            boxes.append((int(row['class']), Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])))\n",
    "        \n",
    "        counter = 0\n",
    "        print('Image:', imname)\n",
    "        \n",
    "        # Create tiles and find intersection with bounding boxes for each tile\n",
    "        for i in range((height // slice_size) + 1):\n",
    "            for j in range((width // slice_size) + 1):\n",
    "                x1 = j * slice_size\n",
    "                y1 = height - (i * slice_size)\n",
    "                x2 = ((j + 1) * slice_size) - 1\n",
    "                y2 = (height - (i + 1) * slice_size) + 1\n",
    "                pol = Polygon([(x1, y1), (x2, y1), (x2, y2), (x1, y2)])\n",
    "                imsaved = False\n",
    "                slice_labels = []\n",
    "\n",
    "                for box in boxes:\n",
    "                    if pol.intersects(box[1]):\n",
    "                        inter = pol.intersection(box[1])\n",
    "                        \n",
    "                        if not imsaved:\n",
    "                            sliced = imr[i*slice_size:(i+1)*slice_size, j*slice_size:(j+1)*slice_size]\n",
    "                            \n",
    "                            # Check if the sliced image is not empty\n",
    "                            if sliced.size == 0:\n",
    "                                continue\n",
    "                                \n",
    "                            sliced_im = Image.fromarray(sliced)\n",
    "                            filename = os.path.basename(imname)\n",
    "                            slice_path = os.path.join(new_image_path, filename.replace(ext, f'_{i}_{j}{ext}'))                            \n",
    "                            slice_labels_path = os.path.join(new_label_path, filename.replace(ext, f'_{i}_{j}.txt'))                            \n",
    "                            print(slice_path)\n",
    "                            sliced_im.save(slice_path)\n",
    "                            imsaved = True                    \n",
    "                        \n",
    "                        # Get smallest rectangular polygon that contains the intersection\n",
    "                        new_box = inter.envelope \n",
    "                        \n",
    "                        # Get central point for the new bounding box \n",
    "                        centre = new_box.centroid\n",
    "                        \n",
    "                        # Get coordinates of polygon vertices\n",
    "                        x, y = new_box.exterior.coords.xy\n",
    "                        \n",
    "                        # Get bounding box width and height normalized to slice size\n",
    "                        new_width = (max(x) - min(x)) / slice_size\n",
    "                        new_height = (max(y) - min(y)) / slice_size\n",
    "                        \n",
    "                        # Normalize central x and invert y for yolo format\n",
    "                        new_x = (centre.coords.xy[0][0] - x1) / slice_size\n",
    "                        new_y = (y1 - centre.coords.xy[1][0]) / slice_size\n",
    "                        \n",
    "                        counter += 1\n",
    "\n",
    "                        slice_labels.append([box[0], new_x, new_y, new_width, new_height])\n",
    "                \n",
    "                if len(slice_labels) > 0:\n",
    "                    slice_df = pd.DataFrame(slice_labels, columns=['class', 'x1', 'y1', 'w', 'h'])\n",
    "                    print(slice_df)\n",
    "                    slice_df.to_csv(slice_labels_path, sep=' ', index=False, header=False, float_format='%.6f')\n",
    "                \n",
    "                if not imsaved and falsepath:\n",
    "                    sliced = imr[i*slice_size:(i+1)*slice_size, j*slice_size:(j+1)*slice_size]\n",
    "                    \n",
    "                    # Check if the sliced image is not empty\n",
    "                    if sliced.size == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    sliced_im = Image.fromarray(sliced)\n",
    "                    filename = os.path.basename(imname)\n",
    "                    slice_path = os.path.join(falsepath, filename.replace(ext, f'_{i}_{j}{ext}'))                \n",
    "                    sliced_im.save(slice_path)\n",
    "                    print('Slice without boxes saved')\n",
    "                    imsaved = True\n",
    "\n",
    "def splitter(target, target_upfolder, ext):\n",
    "    imnames = glob.glob(f'{target}/*{ext}')\n",
    "    names = [os.path.basename(name) for name in imnames]\n",
    "\n",
    "    # Split dataset for train and test\n",
    "    train = []\n",
    "    test = []\n",
    "    for name in names:\n",
    "        train.append(os.path.join(target, name))\n",
    "    print('train:', len(train))\n",
    "    print('test:', len(test))\n",
    "\n",
    "    # Save train part\n",
    "    with open(os.path.join(target_upfolder, 'train.txt'), 'w') as f:\n",
    "        for item in train:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "    # Save test part\n",
    "    with open(os.path.join(target_upfolder, 'test.txt'), 'w') as f:\n",
    "        for item in test:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "\n",
    "# Define variables directly\n",
    "source_images = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k_cropped/images/100k/train/\"\n",
    "source_labels = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k_cropped/labels/100k/train/\"\n",
    "target_images = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k_tiled/images/100k/train/\"\n",
    "target_labels = \"/home/ubaurr/repositorio/traffic_signs/traffic_env/BDD_training/bdd100k_tiled/labels/100k/train/\"\n",
    "ext = \".jpg\"\n",
    "falsefolder = None\n",
    "size = 160\n",
    "\n",
    "# Create the target directories if they don't exist\n",
    "os.makedirs(target_images, exist_ok=True)\n",
    "os.makedirs(target_labels, exist_ok=True)\n",
    "\n",
    "# Create classes.names file\n",
    "classes_names_path = os.path.join(source_images, '../classes.names')\n",
    "if not os.path.exists(classes_names_path):\n",
    "    print('classes.names not found. Creating a default one.')\n",
    "    with open(classes_names_path, 'w') as f:\n",
    "        f.write('traffic sign\\n')\n",
    "\n",
    "# Copy classes.names file\n",
    "upfolder = os.path.join(source_images, '..')\n",
    "target_upfolder = os.path.join(target_images, '..')\n",
    "copyfile(classes_names_path, os.path.join(target_upfolder, 'classes.names'))\n",
    "\n",
    "if falsefolder:\n",
    "    os.makedirs(falsefolder, exist_ok=True)\n",
    "\n",
    "imnames = glob.glob(f'{source_images}/*{ext}')\n",
    "labnames = glob.glob(f'{source_labels}/*.txt')\n",
    "\n",
    "tiler(imnames, target_images, target_labels, falsefolder, size, ext)\n",
    "splitter(target_images, target_upfolder, ext)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
